Deploy:
  input_shape:
  - -1
  - 3
  - -1
  - -1
  model: inference.pdmodel
  output_dtype: int32
  output_op: argmax
  params: inference.pdiparams
  transforms:
  - type: Normalize
Global:
  model_name: PP-LiteSeg-T
Hpi:
  backend_configs:
    paddle_infer:
      trt_dynamic_shapes: &id001
        x:
        - - 1
          - 3
          - 128
          - 256
        - - 1
          - 3
          - 512
          - 1024
        - - 1
          - 3
          - 1024
          - 2048
    tensorrt:
      dynamic_shapes: *id001
